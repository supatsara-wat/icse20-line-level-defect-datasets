File,LineNumber,src
src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,36,import java.util.concurrent.SynchronousQueue;
src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,225,"    executor = new ThreadPoolExecutor(1, numThreads,"
src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,227,        new SynchronousQueue<Runnable>());
src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java,34,import org.apache.hadoop.hbase.HConstants;
src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1148,        if (rs.isSplitting() || rs.isSplit()) {
src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java,297,            if (rit != null && !rit.isClosing() && !rit.isPendingClose()) {
src/test/java/org/apache/hadoop/hbase/master/TestAssignmentManager.java,408,"      processServerShutdownHandler(ct, am);"
src/test/java/org/apache/hadoop/hbase/master/TestAssignmentManager.java,463,"      processServerShutdownHandler(ct, am);"
src/test/java/org/apache/hadoop/hbase/master/TestAssignmentManager.java,483,"  private void processServerShutdownHandler(CatalogTracker ct, AssignmentManager am)"
src/test/java/org/apache/hadoop/hbase/master/TestAssignmentManager.java,493,"    Result r = Mocking.getMetaTableRowResult(REGIONINFO, SERVERNAME_A);"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,459,      int n = 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,460,"      for (Map.Entry<byte[], Object> logWritersEntry : logWriters.entrySet()) {"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,461,        Object o = logWritersEntry.getValue();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,462,        long t1 = EnvironmentEdgeManager.currentTimeMillis();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,463,        if ((t1 - last_report_at) > period) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,464,          last_report_at = t;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,465,          if ((progress_failed == false) && (reporter != null) &&
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,466,              (reporter.progress() == false)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,467,            progress_failed = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,469,        }
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,470,        if (o == BAD_WRITER) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,471,          continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,472,        }
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,473,        n++;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,474,        WriterAndPath wap = (WriterAndPath)o;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,475,        wap.w.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,476,"        LOG.debug(""Closed "" + wap.p);"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,477,"        Path dst = getCompletedRecoveredEditsFilePath(wap.p,"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,478,          outputSink.getRegionMaximumEditLogSeqNum(logWritersEntry.getKey()));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,479,        if (!dst.equals(wap.p) && fs.exists(dst)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,480,"          LOG.warn(""Found existing old edits file. It could be the """
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,481,"              + ""result of a previous failed split attempt. Deleting "" + dst"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,482,"              + "", length="" + fs.getFileStatus(dst).getLen());"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,483,"          if (!fs.delete(dst, false)) {"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,484,"            LOG.warn(""Failed deleting of old "" + dst);"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,485,"            throw new IOException(""Failed deleting of old "" + dst);"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,488,        // Skip the unit tests which create a splitter that reads and writes the
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,489,        // data without touching disk. TestHLogSplit#testThreading is an
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,490,        // example.
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,491,        if (fs.exists(wap.p)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,492,"          if (!fs.rename(wap.p, dst)) {"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,493,"            throw new IOException(""Failed renaming "" + wap.p + "" to "" + dst);"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,495,"          LOG.debug(""Rename "" + wap.p + "" to "" + dst);"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,498,"      String msg = ""Processed "" + editsCount + "" edits across "" + n + "" regions"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,499,"        "" threw away edits for "" + (logWriters.size() - n) + "" regions"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,500,"        ""; log file="" + logPath + "" is corrupted = "" + isCorrupted +"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,501,"        "" progress failed = "" + progress_failed;"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,502,      LOG.info(msg);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,503,      status.markComplete(msg);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,346,"  void joinCluster(final Set<ServerName> onlineServers) throws IOException,"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,358,"    Map<ServerName, List<Pair<HRegionInfo, Result>>> deadServers = rebuildUserRegions(onlineServers);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,371,  /**
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,372,   * Only used for tests
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,373,   * @throws IOException
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,374,   * @throws KeeperException
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,375,   * @throws InterruptedException
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,376,   */
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,377,"  void joinCluster() throws IOException, KeeperException, InterruptedException {"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,378,    joinCluster(serverManager.getOnlineServers().keySet());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,379,  }
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,380,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2512,"  Map<ServerName, List<Pair<HRegionInfo, Result>>> rebuildUserRegions("
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2513,      final Set<ServerName> onlineServers)
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,600,    Set<ServerName> onlineServers = new HashSet<ServerName>(serverManager
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,601,        .getOnlineServers().keySet());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,604,"    splitLogAfterStartup(this.fileSystemManager, onlineServers);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,621,    this.assignmentManager.joinCluster(onlineServers);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,641,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,665,"  protected void splitLogAfterStartup(final MasterFileSystem mfs,"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,666,      Set<ServerName> onlineServers) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,667,    mfs.splitLogAfterStartup(onlineServers);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java,193,  void splitLogAfterStartup(final Set<ServerName> onlineServers) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,203,      throw new PleaseHoldException(message);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,250,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,251,    if (this.deadservers.cleanPreviousInstance(serverName)) {
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java,101,"    protected void splitLogAfterStartup(MasterFileSystem mfs,"
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java,102,        Set<ServerName> onlineServers) {
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java,103,"      super.splitLogAfterStartup(mfs, onlineServers);"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,235,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,738,"          cleanZK(server, this.parent.getRegionInfo());"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,831,"  private static void cleanZK(final Server server, final HRegionInfo hri) {"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,855,"  private static int createNodeSplitting(final ZooKeeperWatcher zkw,"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,856,"      final HRegionInfo region, final ServerName serverName)"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,857,"  throws KeeperException, IOException {"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,914,"  private static int transitionNodeSplitting(final ZooKeeperWatcher zkw,"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,915,"      final HRegionInfo parent,"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,916,"      final ServerName serverName, final int version)"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,917,"  throws KeeperException, IOException {"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HbaseObjectWritable.java,480,"        writeObject(out, list.get(i),"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HbaseObjectWritable.java,481,"                  list.get(i).getClass(), conf);"
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,726,      // Certain znodes must be readable by non-authenticated clients
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,727,      if ((node.equals(zkw.rootServerZNode) == true) ||
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,729,          (node.equals(zkw.clusterIdZNode) == true)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1241,}
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,361,   * @param onlineServers onlined servers when master started
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,429,"    for (Map.Entry<HRegionInfo, ServerName> e: this.regions.entrySet()) {"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,430,      if (!e.getKey().isMetaTable() && e.getValue() != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,431,"        LOG.debug(""Found "" + e + "" out on cluster"");"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,432,        this.failover = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,433,        break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,434,      }
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,435,      if (nodes.contains(e.getKey().getEncodedName())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,436,"        LOG.debug(""Found "" + e.getKey().getRegionNameAsString() + "" in RITs"");"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,437,        // Could be a meta region.
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,438,        this.failover = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,439,        break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2550,"   * @param onlineServers if one region's location belongs to onlineServers, it"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2551,   *          doesn't need to be assigned.
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2627,"          regions.put(regionInfo, regionLocation);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2628,"          addToServers(regionLocation, regionInfo);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,3369,    this.servers.entrySet();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,666,   * @param onlineServers
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java,190,   * @param onlineServers Set of online servers keyed by
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java,191,   * {@link ServerName}
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,183,"  static final String MERGEDIR = ""merges"";"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,88,"  private static final String SPLITDIR = ""splits"";"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,409,        finishInitialization(startupStatus);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,552,/**
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,554,   *
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,566,   *
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,571,  private void finishInitialization(MonitoredTask status)
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,585,"    this.fileSystemManager = new MasterFileSystem(this, this, metrics);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,595,    this.executorService = new ExecutorService(getServerName().toString());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,596,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,597,"    this.serverManager = createServerManager(this, this);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,602,    // initialize master side coprocessors before we start handling requests
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,603,"    status.setStatus(""Initializing master coprocessors"");"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,604,"    this.cpHost = new MasterCoprocessorHost(this, this.conf);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,605,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,606,    // start up all service threads.
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,607,"    status.setStatus(""Initializing master service threads"");"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,608,    startServiceThreads();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,622,    this.assignmentManager.startTimeOutMonitor();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,650,    // Start balancer and meta catalog janitor after meta and regions have
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,651,    // been assigned.
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,652,"    status.setStatus(""Starting balancer and catalog janitor"");"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,653,    this.balancerChore = getAndStartBalancerChore(this);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,654,"    this.catalogJanitorChore = new CatalogJanitor(this, this);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,655,    startCatalogJanitorChore();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,656,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,657,    registerMBean();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,667,    if (this.cpHost != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,668,      // don't let cp initialization errors kill the master
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,669,      try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,670,        this.cpHost.postStartMaster();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,671,      } catch (IOException ioe) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,672,"        LOG.error(""Coprocessor postStartMaster() hook failed"", ioe);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1753,          initializeZKBasedSystemTrackers();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1754,          // Update in-memory structures to reflect our earlier Root/Meta assignment.
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1755,          assignRootAndMeta(status);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1756,          // process RIT if any
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1757,          // TODO: Why does this not call AssignmentManager.joinCluster?  Otherwise
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1758,          // we are not processing dead servers if any.
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1759,          assignmentManager.processDeadServersAndRegionsInTransition();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java,88,      MasterMetrics metrics)
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java,110,      this.splitLogManager.finishInitialization();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,185,  public void finishInitialization() {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,186,"    Threads.setDaemonThreadRunning(timeoutMonitor.getThread(), serverName +"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,187,"      "".splitLogManagerTimeoutMonitor"");"
hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java,168,"      this.mfs = new MasterFileSystem(server, this, null);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,102,   * Run janitorial scan of catalog <code>.META.</code> table looking for
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,103,   * garbage to collect.
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,104,   * @throws IOException
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,106,  void scan() throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,131,"      if (cleanParent(e.getKey(), e.getValue())) cleaned++;"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,134,"      LOG.info(""Scanned "" + count.get() + "" catalog row(s) and gc'd "" + cleaned +"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,137,"      LOG.debug(""Scanned "" + count.get() + "" catalog row(s) and gc'd "" + cleaned +"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ConstantSizeRegionSplitPolicy.java,27, * <p>This is the default split policy.</p>
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionSplitPolicy.java,34, * {@see ConstantSizeRegionSplitPolicy}
hbase-server/src/main/java/org/apache/hadoop/hbase/util/InfoServer.java,128,    int index = p.lastIndexOf(master);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/InfoServer.java,130,"    return index == -1? p: p.substring(0, index);"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/InfoServer.java,132,}
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2416,"     * Compare column, timestamp, and key type (everything except the row)."
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2417,"     * This method is used both in the normal comparator and the ""same-prefix"""
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2418,     * comparator. Note that we are assuming that row portions of both KVs have
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2419,"     * already been parsed and found identical, and we don't validate that"
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2420,     * assumption here.
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2421,     * @param commonPrefix the length of the common prefix of the two
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2422,"     *          key-values being compared, including row length and row"
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2426,      // Compare column family. Start comparing past row and family length.
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2427,      int lcolumnoffset = ROW_LENGTH_SIZE + FAMILY_LENGTH_SIZE +
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2428,          rowlength + loffset;
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2429,      int rcolumnoffset = ROW_LENGTH_SIZE + FAMILY_LENGTH_SIZE +
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2430,          rowlength + roffset;
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2431,      int lcolumnlength = llength - TIMESTAMP_TYPE_SIZE -
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2432,          (lcolumnoffset - loffset);
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2433,      int rcolumnlength = rlength - TIMESTAMP_TYPE_SIZE -
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2434,          (rcolumnoffset - roffset);
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2435,
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2436,"      // If row matches, and no column in the 'left' AND put type is 'minimum',"
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2437,      // then return that left is larger than right.
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2438,
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2439,      // This supports 'last key on a row' - the magic is if there is no column
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2440,"      // in the left operand, and the left operand has a type of '0' - magical"
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2441,"      // value, then we say the left is bigger.  This will let us seek to the"
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2442,      // last key in a row.
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2450,"      // ""lexicographically last column"" (it would be infinitely long).  The"
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2462,"        common = Math.max(0, commonPrefix -"
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2463,            rowlength - ROW_LENGTH_SIZE - FAMILY_LENGTH_SIZE);
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2464,"        common = Math.min(common, Math.min(lcolumnlength, rcolumnlength));"
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2466,
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2467,      final int comparisonResult = Bytes.compareTo(
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2468,"          left, lcolumnoffset + common, lcolumnlength - common,"
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2469,"          right, rcolumnoffset + common, rcolumnlength - common);"
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2470,      if (comparisonResult != 0) {
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2471,        return comparisonResult;
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2473,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java,368,"          if (nextKV == null || comparator.compare(curKV, nextKV) <= 0) {"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2388,    if(destServers.isEmpty()) return;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2391,"    Map<HRegionInfo, ServerName> allRegions ="
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2392,"      MetaReader.fullScan(catalogTracker, this.zkTable.getDisabledTables(), true);"
hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestAssignmentManager.java,869,    builder.setMoreResults(false);
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2463,      // compare the qualifiers.
hbase-server/src/test/java/org/apache/hadoop/hbase/TestKeyValue.java,62,  /**
hbase-server/src/test/java/org/apache/hadoop/hbase/TestKeyValue.java,176,    // meta keys values are not quite right.  A users can enter illegal values
hbase-server/src/test/java/org/apache/hadoop/hbase/TestKeyValue.java,182,    } catch (IllegalArgumentException iae) {
hbase-server/src/test/java/org/apache/hadoop/hbase/TestKeyValue.java,193,    // meta keys values are not quite right.  A users can enter illegal values
hbase-server/src/test/java/org/apache/hadoop/hbase/TestKeyValue.java,199,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1751,"        LOG.debug(""Assigning region "" + state.getRegion().getRegionNameAsString() +"
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,598,    String compressionType;
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,599,    switch (type) {
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,600,"      case LZO: compressionType = ""LZO""; break;"
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,601,"      case GZ: compressionType = ""GZ""; break;"
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,602,"      case SNAPPY: compressionType = ""SNAPPY""; break;"
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,603,"      default: compressionType = ""NONE""; break;"
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,604,    }
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,605,"    return setValue(COMPRESSION, compressionType);"
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,671,    String compressionType;
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,672,    switch (type) {
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,673,"      case LZO: compressionType = ""LZO""; break;"
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,674,"      case GZ: compressionType = ""GZ""; break;"
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,675,"      case SNAPPY: compressionType = ""SNAPPY""; break;"
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,676,"      default: compressionType = ""NONE""; break;"
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,677,    }
hbase-server/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,678,"    return setValue(COMPRESSION_COMPACT, compressionType);"
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,42,import java.util.Random;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,57,import org.apache.hadoop.hbase.protobuf.generated.RPCProtos.RpcResponse.Status;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,65,import org.apache.hadoop.hbase.security.HBaseSaslRpcServer.AuthMethod;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,72,import org.apache.hadoop.hbase.io.DataOutputOutputStream;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,99,  private static final Log LOG =
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,100,"    LogFactory.getLog(""org.apache.hadoop.ipc.HBaseClient"");"
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,872,        Call call = calls.remove(id);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,887,    if (!killed) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,888,      join();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,889,    }
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,345,      // add 2nd daughter first (see HBASE-4335)
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,346,"      MetaEditor.addDaughter(server.getCatalogTracker(),"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,347,"          b.getRegionInfo(), services.getServerName());"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,348,"      MetaEditor.addDaughter(server.getCatalogTracker(),"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,349,"          a.getRegionInfo(), services.getServerName());"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,400,"  /* package */void transitionZKNode(final Server server, HRegion a, HRegion b)"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,424,        } while (this.znodeVersion != -1);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,458,"    transitionZKNode(server, regions.getFirst(), regions.getSecond());"
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestEndToEndSplitTransaction.java,139,"    split.transitionZKNode(server, regions.getFirst(), regions.getSecond());"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,2539,"      FIRST_REGION_STARTKEY_NOT_EMPTY, DUPE_STARTKEYS,"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,97,"    HTable table = new HTable(conf, tableName);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,98,
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,112,"    table.coprocessorExec(AggregateProtocol.class, scan.getStartRow(), scan"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,113,"        .getStopRow(), new Batch.Call<AggregateProtocol, R>() {"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,114,      @Override
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,115,      public R call(AggregateProtocol instance) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,116,"        return instance.getMax(ci, scan);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,118,"    }, aMaxCallBack);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,161,"    HTable table = new HTable(conf, tableName);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,163,"    table.coprocessorExec(AggregateProtocol.class, scan.getStartRow(), scan"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,164,"        .getStopRow(), new Batch.Call<AggregateProtocol, R>() {"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,166,      @Override
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,167,      public R call(AggregateProtocol instance) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,168,"        return instance.getMin(ci, scan);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,170,"    }, minCallBack);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,204,"    HTable table = new HTable(conf, tableName);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,205,"    table.coprocessorExec(AggregateProtocol.class, scan.getStartRow(), scan"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,206,"        .getStopRow(), new Batch.Call<AggregateProtocol, Long>() {"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,207,      @Override
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,208,      public Long call(AggregateProtocol instance) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,209,"        return instance.getRowNum(ci, scan);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,211,"    }, rowNum);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,240,"    HTable table = new HTable(conf, tableName);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,241,"    table.coprocessorExec(AggregateProtocol.class, scan.getStartRow(), scan"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,242,"        .getStopRow(), new Batch.Call<AggregateProtocol, S>() {"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,243,      @Override
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,244,      public S call(AggregateProtocol instance) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,245,"        return instance.getSum(ci, scan);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,247,"    }, sumCallBack);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,277,"    HTable table = new HTable(conf, tableName);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,278,"    table.coprocessorExec(AggregateProtocol.class, scan.getStartRow(), scan"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,279,"        .getStopRow(), new Batch.Call<AggregateProtocol, Pair<S, Long>>() {"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,280,      @Override
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,281,"      public Pair<S, Long> call(AggregateProtocol instance) throws IOException {"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,282,"        return instance.getAvg(ci, scan);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,284,"    }, avgCallBack);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,340,"    HTable table = new HTable(conf, tableName);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,341,"    table.coprocessorExec(AggregateProtocol.class, scan.getStartRow(), scan"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,342,"        .getStopRow(),"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,343,"        new Batch.Call<AggregateProtocol, Pair<List<S>, Long>>() {"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,344,          @Override
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,345,"          public Pair<List<S>, Long> call(AggregateProtocol instance)"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,346,              throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,347,"            return instance.getStd(ci, scan);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,348,          }
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,350,"        }, stdCallback);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,415,"    HTable table = new HTable(conf, tableName);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,416,"    table.coprocessorExec(AggregateProtocol.class, scan.getStartRow(), scan"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,417,"        .getStopRow(),"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,418,"        new Batch.Call<AggregateProtocol, List<S>>() {"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,419,          @Override
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,420,          public List<S> call(AggregateProtocol instance)
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,421,              throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,422,"            return instance.getMedian(ci, scan);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,423,          }
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,425,"        }, stdCallback);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,467,"    HTable table = new HTable(conf, tableName);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,468,    int cacheSize = scan2.getCaching();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,469,    if (!scan2.getCacheBlocks() || scan2.getCaching() < 2) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,470,      scan2.setCacheBlocks(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,471,      cacheSize = 5;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,472,      scan2.setCaching(cacheSize);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,473,    }
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,474,    ResultScanner scanner = table.getScanner(scan2);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,475,    Result[] results = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,476,    byte[] qualifier = quals.pollFirst();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,477,    // qualifier for the weight column
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,478,    byte[] weightQualifier = weighted ? quals.pollLast() : qualifier;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,479,    R value = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,499,        }
hbase-server/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java,502,      scanner.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2384,    // Get all available servers
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2385,    List<ServerName> destServers = serverManager.createDestinationServersList();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2386,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2387,    // If there are no servers we need not proceed with region assignment.
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2388,    if (destServers.isEmpty()) return;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2389,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java,586,    sf.createReader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,585,   *  - the 'hbase.master.wait.on.regionservers.timeout' is reached
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,590,   *      'hbase.master.wait.on.regionservers.interval' time
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,599,"    getLong(""hbase.master.wait.on.regionservers.timeout"", 4500);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,601,"    getInt(""hbase.master.wait.on.regionservers.mintostart"", 1);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,602,    final int maxToStart = this.master.getConfiguration().
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,603,"    getInt(""hbase.master.wait.on.regionservers.maxtostart"", Integer.MAX_VALUE);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,614,        slept < timeout &&
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,616,        (lastCountChange+interval > now || count < minToStart)
hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java,658,"    conf.setInt(""hbase.master.wait.on.regionservers.mintostart"", numSlaves);"
hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java,659,"    conf.setInt(""hbase.master.wait.on.regionservers.maxtostart"", numSlaves);"
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java,72,"    TESTUTIL.getConfiguration().setClass(HConstants.MASTER_IMPL,"
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java,73,"        TestingMaster.class, HMaster.class);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,589,   *      'hbase.master.wait.on.regionservers.interval' time AND
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,590,   *   the 'hbase.master.wait.on.regionservers.timeout' is reached
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,599,"      getLong(""hbase.master.wait.on.regionservers.timeout"", 4500);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,601,"      getInt(""hbase.master.wait.on.regionservers.mintostart"", 1);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,602,    int maxToStart = this.master.getConfiguration().
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,603,"      getInt(""hbase.master.wait.on.regionservers.maxtostart"", Integer.MAX_VALUE);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,604,    if (maxToStart < minToStart) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,605,        LOG.warn(String.format(
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,606,"            ""The value of 'hbase.master.wait.on.regionservers.maxtostart' (%d)"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,607,"            "" is set less than 'hbase.master.wait.on.regionservers.mintostart'"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,608,"            "" (%d), ignoring."", maxToStart, minToStart));"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,609,        maxToStart = Integer.MAX_VALUE;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,610,    }
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,622,        (lastCountChange+interval > now || timeout > slept || count < minToStart)
hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java,658,    String count = String.valueOf(numSlaves);
hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java,659,"    conf.setIfUnset(""hbase.master.wait.on.regionservers.mintostart"", count);"
hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java,660,"    conf.setIfUnset(""hbase.master.wait.on.regionservers.maxtostart"", count);"
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java,72,    Configuration conf = TESTUTIL.getConfiguration();
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java,73,"    conf.setClass(HConstants.MASTER_IMPL, TestingMaster.class, HMaster.class);"
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java,74,"    conf.setInt(""hbase.master.wait.on.regionservers.mintostart"", 3);"
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java,75,"    conf.setInt(""hbase.master.wait.on.regionservers.maxtostart"", 4);"
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java,76,
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,84,  private final List<String> otherRegionServers;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,125,    List<String> otherRSs =
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,126,        this.zkHelper.getRegisteredRegionServers();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,130,    this.otherRegionServers = otherRSs == null ? new ArrayList<String>() : otherRSs;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,420,      refreshRegionServersList(path);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,431,      boolean cont = refreshRegionServersList(path);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,447,      refreshRegionServersList(path);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,450,    private boolean refreshRegionServersList(String path) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,454,      List<String> newRsList = (zkHelper.getRegisteredRegionServers());
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,455,      if (newRsList == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,456,        return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,457,      } else {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,458,        synchronized (otherRegionServers) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,459,          otherRegionServers.clear();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,460,          otherRegionServers.addAll(newRsList);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,461,        }
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,462,      }
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,463,      return true;
hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java,205,  @Test
hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java,356,"        ""testMasterAddressManagerFromZK"","
hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java,357,        null);
hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java,360,"    zk.setACL(""/"", ZooDefs.Ids.CREATOR_ALL_ACL, -1);"
hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java,361,"    zk.create(aclZnode, null, ZooDefs.Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);"
hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java,362,    zk.close();
hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java,647,"    TextOutputFormat.setOutputPath(job, new Path(inputDir,""outputs""));"
hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java,666,    FileSystem fs = FileSystem.get(c);
hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java,667,    if (!fs.exists(PERF_EVAL_DIR)) {
hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java,668,      fs.mkdirs(PERF_EVAL_DIR);
hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java,669,    }
hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java,671,"    Path subdir = new Path(PERF_EVAL_DIR, formatter.format(new Date()));"
hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java,672,    fs.mkdirs(subdir);
hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java,673,"    Path inputFile = new Path(subdir, ""input.txt"");"
hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java,698,    return subdir;
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/FilterList.java,77,    this.filters = rowFilters;
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/FilterList.java,86,    this.filters = Arrays.asList(rowFilters);
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/FilterList.java,105,    this.filters = rowFilters;
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/FilterList.java,116,    this.filters = Arrays.asList(rowFilters);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,3099,"    System.err.println(""   -repairHoles      Shortcut for -fixAssignments -fixMeta -fixHdfsHoles -fixHdfsOrphans"");"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SkipFilter.java,43," * scan.setFilter(new SkipFilter(new ValueFilter(CompareOp.EQUAL,"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SkipFilter.java,46, * Any row which contained a column whose value was 0 will be filtered out.
hbase-server/src/main/java/org/apache/hadoop/hbase/util/hbck/OfflineMetaRepair.java,46,  private static final Log LOG = LogFactory.getLog(HBaseFsck.class.getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java,567,    if (!srcFs.equals(fs)) {
hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java,1655,"      assertTrue(""Timed out waiting for table "" + Bytes.toStringBinary(table),"
hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java,1656,          System.currentTimeMillis() - startWait < timeoutMillis);
hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestClassLoading.java,243,"    TEST_UTIL.waitTableAvailable(htd.getName(), 5000);"
hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestClassLoading.java,286,"    TEST_UTIL.waitTableAvailable(htd.getName(), 5000);"
hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestClassLoading.java,312,"    TEST_UTIL.waitTableAvailable(htd.getName(), 5000);"
hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestClassLoading.java,380,"    TEST_UTIL.waitTableAvailable(htd.getName(), 5000);"
hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestClassLoading.java,485,"    TEST_UTIL.waitTableAvailable(htd.getName(), 5000);"
hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestClassLoading.java,557,"    TEST_UTIL.waitTableAvailable(userTD1.getName(), 5000);"
hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestClassLoading.java,576,"    TEST_UTIL.waitTableAvailable(htd2.getName(), 5000);"
hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,205,      if (numChosen != 1) {
hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,207,"            Arrays.toString(values()) + "" has to be specified"");"
hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,209,"      LOG.info(""Setting thrift server to "" + chosenType.option);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1328,"    final Map<byte[],R> results = new TreeMap<byte[],R>("
hbase-server/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1329,        Bytes.BYTES_COMPARATOR);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,156,      HashSet<HRegionInfo> parentNotCleaned = new HashSet<HRegionInfo>(); //regions whose parents are still around
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,158,"        if (!parentNotCleaned.contains(e.getKey()) && cleanParent(e.getKey(), e.getValue())) {"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,161,"          // We could not clean the parent, so it's daughters should not be cleaned either (HBASE-6160)"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,162,"          parentNotCleaned.add(getDaughterRegionInfo(e.getValue(), HConstants.SPLITA_QUALIFIER));"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,163,"          parentNotCleaned.add(getDaughterRegionInfo(e.getValue(), HConstants.SPLITB_QUALIFIER));"
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKTable.java,354,   * Sets the ENABLED state in the cache and deletes the zookeeper node. Fails
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKTable.java,355,   * silently if the node is not in enabled in zookeeper
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/ClientCache.java,35," * look at {@link HBaseClient#HBaseClient(Class, Configuration, SocketFactory)}"
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/ClientCache.java,55,"  protected synchronized HBaseClient getClient(Configuration conf,"
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/ClientCache.java,56,      SocketFactory factory) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/ClientCache.java,60,"      client = new HBaseClient(conf, factory);"
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,266,    public Connection(ConnectionId remoteId) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,362,     * a listener; synchronized.
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,363,     * Returns false if called during shutdown.
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,365,     * @return true if the call was added.
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,367,    protected synchronized boolean addCall(Call call) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,368,      if (shouldCloseConnection.get())
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,369,        return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,370,"      calls.put(call.id, call);"
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,371,      notify();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,372,      return true;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,701,            if (authMethod == AuthMethod.KERBEROS) {;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,1040,   * @param valueClass value class
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,1300,    do {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,1301,      synchronized (connections) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,1302,        connection = connections.get(remoteId);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,1303,        if (connection == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,1304,          connection = new Connection(remoteId);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,1305,"          connections.put(remoteId, connection);"
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,1306,        }
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseClient.java,1308,    } while (!connection.addCall(call));
hbase-server/src/main/java/org/apache/hadoop/hbase/util/EnvironmentEdgeManager.java,53,  static void reset() {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/EnvironmentEdgeManager.java,63,  static void injectEdge(EnvironmentEdge edge) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/RetriesExhaustedWithDetailsException.java,132,      if (t instanceof NoSuchColumnFamilyException) {
hbase-server/src/main/java/org/apache/hadoop/hbase/metrics/MetricsMBeanBase.java,78,      if (metric instanceof MetricsRate || metric instanceof MetricsString) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,146,"          if (getComparator().compare(key, offset, length, splitkey, 0,"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,147,              splitkey.length) < 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1714,"    HFileScanner scanner = r.getHFileReader().getScanner(true, true, false);"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,57,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,58,  private byte[] firstKey = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,59,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,60,  private boolean firstKeySeeked = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,150,          byte[] fk = getFirstKey();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,151,          // This will be null when the file is empty in which we can not seekBefore to any key
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,152,          if (fk == null) return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,153,"          if (getComparator().compare(key, offset, length, fk, 0,"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,154,              fk.length) <= 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,283,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,284,  @Override
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,285,  public byte[] getFirstKey() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,286,    if (!firstKeySeeked) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,287,"      HFileScanner scanner = getScanner(true, true, false);"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,288,      try {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,289,        if (scanner.seekTo()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,290,          this.firstKey = Bytes.toBytes(scanner.getKey());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,291,        }
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,292,        firstKeySeeked = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,293,      } catch (IOException e) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,294,"        LOG.warn(""Failed seekTo first KV in the file"", e);"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,295,      }
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,296,    }
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,297,    return this.firstKey;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,298,  }
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1701,    if (fk == null) return;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1715,"    HFileScanner scanner = r.getScanner(true, true, false);"
hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java,198,      // Try to seek before the splitKey in the top file
hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java,199,"      foundKeyValue = doTestOfSeekBefore(p, fs, top, midKV, cacheConf);"
hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java,200,      assertNull(foundKeyValue);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2298,      if (walEdit.size() > 0 &&
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2299,          (this.regionInfo.isMetaRegion() ||
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2300,           !this.htableDescriptor.isDeferredLogFlush())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2301,        this.log.sync(txid);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4501,          if (txid != 0 &&
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4502,              (this.regionInfo.isMetaRegion() ||
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4503,               !this.htableDescriptor.isDeferredLogFlush())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4504,            this.log.sync(txid);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4753,        this.log.sync(txid); // sync the transaction log outside the rowlock
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4881,        this.log.sync(txid); // sync the transaction log outside the rowlock
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4979,        this.log.sync(txid); // sync the transaction log outside the rowlock
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java,1196,   * This thread is responsible to call syncFs and buffer up the writers while
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java,1197,   * it happens.
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java,1199,   class LogSyncer extends HasThread {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java,256,      if (ke instanceof ConnectionLossException
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java,257,          || ke instanceof SessionExpiredException) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java,258,        LOG.warn(
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java,259,"            ""Lost the ZooKeeper connection for peer "" + peer.getClusterKey(),"
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java,260,            ke);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java,261,        try {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java,262,          peer.reloadZkWatcher();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java,263,        } catch(IOException io) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java,264,          LOG.warn(
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java,265,"              ""Creation of ZookeeperWatcher failed for peer """
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java,266,"                  + peer.getClusterKey(), io);"
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java,267,        }
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationZookeeper.java,268,      }
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,192,      this.clusterId = UUID.fromString(ZKClusterId.readClusterIdZNode(zkHelper
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,193,          .getZookeeperWatcher()));
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,254,    try {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,255,      this.peerClusterId = UUID.fromString(ZKClusterId
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,256,          .readClusterIdZNode(zkHelper.getPeerClusters().get(peerId).getZkw()));
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,257,    } catch (KeeperException ke) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,258,"      this.terminate(""Could not read peer's cluster id"", ke);"
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,273,    int sleepMultiplier = 1;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,166,"    HTableDescriptor htd = getTableDescriptor(this.fs, this.rootdir, tablename);"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,261,"  private static FileStatus getTableInfoPath(final FileSystem fs,"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,378,"     return getTableDescriptor(fs, hbaseRootDir, Bytes.toString(tableName));"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,382,"      Path hbaseRootDir, String tableName) {"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,384,    try {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,385,"      htd = getTableDescriptor(fs, FSUtils.getTablePath(hbaseRootDir, tableName));"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,386,    } catch (NullPointerException e) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,387,"      LOG.debug(""Exception during readTableDecriptor. Current table name = "" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,388,"        tableName , e);"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,389,    } catch (IOException ioe) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,390,"      LOG.debug(""Exception during readTableDecriptor. Current table name = "" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,391,"        tableName , ioe);"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,400,    if (status == null) return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,715,"          LOG.error(""Unable to read .tableinfo from "" + hbaseRoot, ioe);"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,716,          throw ioe;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,2643,"      ORPHAN_HDFS_REGION, LINGERING_SPLIT_PARENT"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,145,"          if (getComparator().compare(key, offset, length, splitkey, 0,"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,146,              splitkey.length) < 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1714,"    HFileScanner scanner = r.getHFileReader().getScanner(true, true, false);"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2158,        } catch (DoNotRetryIOException dnrioe) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2159,"          LOG.warn(""No such column family in batch mutation"", dnrioe);"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2161,"              OperationStatusCode.SANITY_CHECK_FAILURE, dnrioe.getMessage());"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2734,      long now) throws DoNotRetryIOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2743,"          throw new DoNotRetryIOException(""Timestamp for KV out of range """
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3925,        if (codes[i].getOperationStatusCode() != OperationStatusCode.SUCCESS) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3926,          result = ResponseConverter.buildActionResult(
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3927,            new DoNotRetryIOException(codes[i].getExceptionMsg()));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3928,"          builder.setResult(i, result);"
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java,578,      } catch (DoNotRetryIOException e) {
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java,619,        assertEquals((i == 5) ? OperationStatusCode.SANITY_CHECK_FAILURE :
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java,657,        assertEquals((i == 5) ? OperationStatusCode.SANITY_CHECK_FAILURE :
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java,674,        assertEquals((i == 5) ? OperationStatusCode.SANITY_CHECK_FAILURE :
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java,1247,      } catch (DoNotRetryIOException ioe) {
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/ScannerModel.java,694,    builder.setBatch(batch);
examples/thrift/DemoClient.java,175,"        mutations.add(new Mutation(false, ByteBuffer.wrap(bytes(""entry:foo"")), ByteBuffer.wrap(invalid)));"
examples/thrift/DemoClient.java,176,"        client.mutateRow(ByteBuffer.wrap(t), ByteBuffer.wrap(bytes(""foo"")), mutations);"
examples/thrift/DemoClient.java,180,"        mutations.add(new Mutation(false, ByteBuffer.wrap(bytes(""entry:"")), ByteBuffer.wrap(bytes(""""))));"
examples/thrift/DemoClient.java,181,"        client.mutateRow(ByteBuffer.wrap(t), ByteBuffer.wrap(bytes("""")), mutations);"
examples/thrift/DemoClient.java,185,"        mutations.add(new Mutation(false, ByteBuffer.wrap(bytes(""entry:foo"")), ByteBuffer.wrap(valid)));"
examples/thrift/DemoClient.java,186,"        client.mutateRow(ByteBuffer.wrap(t), ByteBuffer.wrap(valid), mutations);"
examples/thrift/DemoClient.java,192,"        mutations.add(new Mutation(false, ByteBuffer.wrap(bytes(""entry:foo"")), ByteBuffer.wrap(invalid)));"
examples/thrift/DemoClient.java,193,"        client.mutateRow(ByteBuffer.wrap(t), ByteBuffer.wrap(invalid), mutations);"
examples/thrift/DemoClient.java,201,"        int scanner = client.scannerOpen(ByteBuffer.wrap(t), ByteBuffer.wrap(bytes("""")), columnNames);"
examples/thrift/DemoClient.java,222,"            mutations.add(new Mutation(false, ByteBuffer.wrap(bytes(""unused:"")), ByteBuffer.wrap(bytes(""DELETE_ME""))));"
examples/thrift/DemoClient.java,223,"            client.mutateRow(ByteBuffer.wrap(t), ByteBuffer.wrap(row), mutations);"
examples/thrift/DemoClient.java,224,"            printRow(client.getRow(ByteBuffer.wrap(t), ByteBuffer.wrap(row)));"
examples/thrift/DemoClient.java,225,"            client.deleteAllRow(ByteBuffer.wrap(t), ByteBuffer.wrap(row));"
examples/thrift/DemoClient.java,228,"            mutations.add(new Mutation(false, ByteBuffer.wrap(bytes(""entry:num"")), ByteBuffer.wrap(bytes(""0""))));"
examples/thrift/DemoClient.java,229,"            mutations.add(new Mutation(false, ByteBuffer.wrap(bytes(""entry:foo"")), ByteBuffer.wrap(bytes(""FOO""))));"
examples/thrift/DemoClient.java,230,"            client.mutateRow(ByteBuffer.wrap(t), ByteBuffer.wrap(row), mutations);"
examples/thrift/DemoClient.java,231,"            printRow(client.getRow(ByteBuffer.wrap(t), ByteBuffer.wrap(row)));"
examples/thrift/DemoClient.java,243,"            client.mutateRow(ByteBuffer.wrap(t), ByteBuffer.wrap(row), mutations);"
examples/thrift/DemoClient.java,244,"            printRow(client.getRow(ByteBuffer.wrap(t), ByteBuffer.wrap(row)));"
examples/thrift/DemoClient.java,247,"            mutations.add(new Mutation(false, ByteBuffer.wrap(bytes(""entry:num"")), ByteBuffer.wrap(bytes(Integer.toString(i)))));"
examples/thrift/DemoClient.java,248,"            mutations.add(new Mutation(false, ByteBuffer.wrap(bytes(""entry:sqr"")), ByteBuffer.wrap(bytes(Integer.toString(i * i)))));"
examples/thrift/DemoClient.java,249,"            client.mutateRow(ByteBuffer.wrap(t), ByteBuffer.wrap(row), mutations);"
examples/thrift/DemoClient.java,250,"            printRow(client.getRow(ByteBuffer.wrap(t), ByteBuffer.wrap(row)));"
examples/thrift/DemoClient.java,267,"            client.mutateRowTs(ByteBuffer.wrap(t), ByteBuffer.wrap(row), mutations, 1); // shouldn't override latest"
examples/thrift/DemoClient.java,268,"            printRow(client.getRow(ByteBuffer.wrap(t), ByteBuffer.wrap(row)));"
examples/thrift/DemoClient.java,270,"            List<TCell> versions = client.getVer(ByteBuffer.wrap(t), ByteBuffer.wrap(row), ByteBuffer.wrap(bytes(""entry:num"")), 10);"
examples/thrift/DemoClient.java,278,"            List<TCell> result = client.get(ByteBuffer.wrap(t), ByteBuffer.wrap(row), ByteBuffer.wrap(bytes(""entry:foo"")));"
examples/thrift/DemoClient.java,298,"        scanner = client.scannerOpenWithStop(ByteBuffer.wrap(t), ByteBuffer.wrap(bytes(""00020"")), ByteBuffer.wrap(bytes(""00040"")),"
examples/thrift/DemoClient.java,299,                columnNames);
hbase-server/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java,104,"      return this.toString() + ""-"" + serverName;"
hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestMultiSlaveReplication.java,176,"    checkRow(row, 1, htable2, htable3);"
hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestMultiSlaveReplication.java,186,
hbase-server/src/main/java/org/apache/hadoop/hbase/fs/HFileSystem.java,97,    addLocationsOrderInterceptor(conf);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,467,"      HConstants.HBASE_CHECKSUM_VERIFICATION, true);"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java,687,    // Always cache Bloom filter blocks.
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV1.java,688,"    ByteBuffer buf = getMetaBlock(HFileWriterV1.BLOOM_FILTER_META_KEY, true);"
hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java,1096,
hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java,1135,"  public int loadRegion(final HRegion r, final byte[] f)"
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java,21,import com.google.common.collect.ImmutableList;
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java,22,
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java,35,import org.apache.hadoop.hbase.*;
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransaction.java,196,"    final int rowcount = TEST_UTIL.loadRegion(this.parent, CF);"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,298,              if (cause == null || (!(cause instanceof NotServingRegionException)
hbase-server/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,299,                  && !(cause instanceof RegionServerStoppedException))) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java,70,
hbase-server/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java,141,"            RequestConverter.buildScanRequest(scannerId, caching, false);"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23718,"      ""storeLimit\030\013 \001(\r\022\023\n\013storeOffset\030\014 \001(\r\""\203\001"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23722,"      ""anner\030\005 \001(\010\""\\\n\014ScanResponse\022\027\n\006result\030\001 "" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23723,"      ""\003(\0132\007.Result\022\021\n\tscannerId\030\002 \001(\004\022\023\n\013moreR"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23724,"      ""esults\030\003 \001(\010\022\013\n\003ttl\030\004 \001(\r\""?\n\016LockRowRequ"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23725,"      ""est\022 \n\006region\030\001 \002(\0132\020.RegionSpecifier\022\013\n"","
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23726,"      ""\003row\030\002 \003(\014\"".\n\017LockRowResponse\022\016\n\006lockId\030"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23727,"      ""\001 \002(\004\022\013\n\003ttl\030\002 \001(\r\""D\n\020UnlockRowRequest\022 "" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23728,"      ""\n\006region\030\001 \002(\0132\020.RegionSpecifier\022\016\n\006lock"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23729,"      ""Id\030\002 \002(\004\""\023\n\021UnlockRowResponse\""\260\001\n\024BulkLo"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23730,"      ""adHFileRequest\022 \n\006region\030\001 \002(\0132\020.RegionS"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23731,"      ""pecifier\0224\n\nfamilyPath\030\002 \003(\0132 .BulkLoadH"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23732,"      ""FileRequest.FamilyPath\022\024\n\014assignSeqNum\030\003"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23733,"      "" \001(\010\032*\n\nFamilyPath\022\016\n\006family\030\001 \002(\014\022\014\n\004pa"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23734,"      ""th\030\002 \002(\t\""\'\n\025BulkLoadHFileResponse\022\016\n\006loa"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23735,"      ""ded\030\001 \002(\010\""\203\001\n\004Exec\022\013\n\003row\030\001 \002(\014\022\024\n\014proto"","
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23736,"      ""colName\030\002 \002(\t\022\022\n\nmethodName\030\003 \002(\t\022!\n\010pro"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23737,"      ""perty\030\004 \003(\0132\017.NameStringPair\022!\n\tparamete"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23738,"      ""r\030\005 \003(\0132\016.NameBytesPair\""O\n\026ExecCoprocess"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23739,"      ""orRequest\022 \n\006region\030\001 \002(\0132\020.RegionSpecif"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23740,"      ""ier\022\023\n\004call\030\002 \002(\0132\005.Exec\""8\n\027ExecCoproces"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23741,"      ""sorResponse\022\035\n\005value\030\001 \002(\0132\016.NameBytesPa"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23742,"      ""ir\""_\n\026CoprocessorServiceCall\022\013\n\003row\030\001 \002("" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23743,"      ""\014\022\023\n\013serviceName\030\002 \002(\t\022\022\n\nmethodName\030\003 \002"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23744,"      ""(\t\022\017\n\007request\030\004 \002(\014\""d\n\031CoprocessorServic"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23745,"      ""eRequest\022 \n\006region\030\001 \002(\0132\020.RegionSpecifi"","
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23746,"      ""er\022%\n\004call\030\002 \002(\0132\027.CoprocessorServiceCal"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23747,"      ""l\""]\n\032CoprocessorServiceResponse\022 \n\006regio"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23748,"      ""n\030\001 \002(\0132\020.RegionSpecifier\022\035\n\005value\030\002 \002(\013"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23749,"      ""2\016.NameBytesPair\""N\n\013MultiAction\022\027\n\006mutat"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23750,"      ""e\030\001 \001(\0132\007.Mutate\022\021\n\003get\030\002 \001(\0132\004.Get\022\023\n\004e"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23751,"      ""xec\030\003 \001(\0132\005.Exec\""P\n\014ActionResult\022\035\n\005valu"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23752,"      ""e\030\001 \001(\0132\016.NameBytesPair\022!\n\texception\030\002 \001"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23753,"      ""(\0132\016.NameBytesPair\""^\n\014MultiRequest\022 \n\006re"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23754,"      ""gion\030\001 \002(\0132\020.RegionSpecifier\022\034\n\006action\030\002"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23755,"      "" \003(\0132\014.MultiAction\022\016\n\006atomic\030\003 \001(\010\"".\n\rMu"","
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23756,"      ""ltiResponse\022\035\n\006result\030\001 \003(\0132\r.ActionResu"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23757,"      ""lt2\331\003\n\rClientService\022 \n\003get\022\013.GetRequest"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23758,"      ""\032\014.GetResponse\022)\n\006mutate\022\016.MutateRequest"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23759,"      ""\032\017.MutateResponse\022#\n\004scan\022\014.ScanRequest\032"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23760,"      ""\r.ScanResponse\022,\n\007lockRow\022\017.LockRowReque"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23761,"      ""st\032\020.LockRowResponse\0222\n\tunlockRow\022\021.Unlo"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23762,"      ""ckRowRequest\032\022.UnlockRowResponse\022>\n\rbulk"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23763,"      ""LoadHFile\022\025.BulkLoadHFileRequest\032\026.BulkL"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23764,"      ""oadHFileResponse\022D\n\017execCoprocessor\022\027.Ex"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23765,"      ""ecCoprocessorRequest\032\030.ExecCoprocessorRe"","
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23766,"      ""sponse\022F\n\013execService\022\032.CoprocessorServi"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23767,"      ""ceRequest\032\033.CoprocessorServiceResponse\022&"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23768,"      ""\n\005multi\022\r.MultiRequest\032\016.MultiResponseBB"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23769,"      ""\n*org.apache.hadoop.hbase.protobuf.gener"" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23770,"      ""atedB\014ClientProtosH\001\210\001\001\240\001\001"""
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,23878,"              new java.lang.String[] { ""Region"", ""Scan"", ""ScannerId"", ""NumberOfRows"", ""CloseScanner"", },"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,283,"  final ConcurrentHashMap<String, RegionScanner> scanners ="
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,284,"      new ConcurrentHashMap<String, RegionScanner>();"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,563,    return scanners.get(scannerIdString);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1143,"    for (Map.Entry<String, RegionScanner> e : this.scanners.entrySet()) {"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1145,        e.getValue().close();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2539,      RegionScanner s = scanners.remove(this.scannerName);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2540,      if (s != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2844,"      RegionScanner existing = scanners.putIfAbsent(scannerName, s);"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3087,          scanner = scanners.get(scannerName);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3088,          if (scanner == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3196,          scanner = scanners.remove(scannerName);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3197,          if (scanner != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/JVMClusterUtil.java,85,      server = hrsc.getConstructor(Configuration.class).newInstance(c);
hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientScannerRPCTimeout.java,110,        if (!slept && this.tableScannerId == request.getScannerId()
hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientScannerRPCTimeout.java,111,            && seqNoToSleepOn == request.getNextCallSeq()) {
hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientScannerRPCTimeout.java,118,"        return super.scan(controller, request);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,684,   *  - the 'hbase.master.wait.on.regionservers.timeout' is reached
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,689,   *      'hbase.master.wait.on.regionservers.interval' time
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,696,"      getLong(""hbase.master.wait.on.regionservers.interval"", 1500);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,698,"    getLong(""hbase.master.wait.on.regionservers.timeout"", 4500);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,699,    final int minToStart = this.master.getConfiguration().
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,700,"    getInt(""hbase.master.wait.on.regionservers.mintostart"", 1);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,701,    final int maxToStart = this.master.getConfiguration().
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,702,"    getInt(""hbase.master.wait.on.regionservers.maxtostart"", Integer.MAX_VALUE);"
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,713,        slept < timeout &&
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,715,        (lastCountChange+interval > now || count < minToStart)
hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java,733,    //  regions servers are connected.
hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java,734,"    conf.setInt(""hbase.master.wait.on.regionservers.mintostart"", numSlaves);"
hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java,735,"    conf.setInt(""hbase.master.wait.on.regionservers.maxtostart"", numSlaves);"
hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java,447,  @Test(timeout = 180000)
hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java,160,"    conf.setInt(""hbase.master.wait.on.regionservers.mintostart"", 3);"
hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java,161,"    conf.setInt(""hbase.master.wait.on.regionservers.maxtostart"", 3);"
hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java,463,"    conf.setInt(""hbase.master.wait.on.regionservers.mintostart"", 1);"
hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFailover.java,464,"    conf.setInt(""hbase.master.wait.on.regionservers.maxtostart"", 2);"
hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterNoCluster.java,250,"    conf.setInt(""hbase.master.wait.on.regionservers.mintostart"", 1);"
hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterNoCluster.java,251,"    conf.setInt(""hbase.master.wait.on.regionservers.maxtostart"", 1);"
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java,72,"    TESTUTIL.getConfiguration().setClass(HConstants.MASTER_IMPL,"
hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestRSKilledWhenMasterInitializing.java,73,"        TestingMaster.class, HMaster.class);"
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,32,  public static AtomicLong tot_mgr_log_split_batch_start = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,33,  public static AtomicLong tot_mgr_log_split_batch_success =
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,34,    new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,35,  public static AtomicLong tot_mgr_log_split_batch_err = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,36,  public static AtomicLong tot_mgr_new_unexpected_hlogs = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,37,  public static AtomicLong tot_mgr_log_split_start = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,38,  public static AtomicLong tot_mgr_log_split_success = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,39,  public static AtomicLong tot_mgr_log_split_err = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,40,  public static AtomicLong tot_mgr_node_create_queued = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,41,  public static AtomicLong tot_mgr_node_create_result = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,42,  public static AtomicLong tot_mgr_node_already_exists = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,43,  public static AtomicLong tot_mgr_node_create_err = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,44,  public static AtomicLong tot_mgr_node_create_retry = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,45,  public static AtomicLong tot_mgr_get_data_queued = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,46,  public static AtomicLong tot_mgr_get_data_result = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,47,  public static AtomicLong tot_mgr_get_data_nonode = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,48,  public static AtomicLong tot_mgr_get_data_err = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,49,  public static AtomicLong tot_mgr_get_data_retry = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,50,  public static AtomicLong tot_mgr_node_delete_queued = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,51,  public static AtomicLong tot_mgr_node_delete_result = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,52,  public static AtomicLong tot_mgr_node_delete_err = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,53,  public static AtomicLong tot_mgr_resubmit = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,54,  public static AtomicLong tot_mgr_resubmit_failed = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,55,  public static AtomicLong tot_mgr_null_data = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,56,  public static AtomicLong tot_mgr_orphan_task_acquired = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,57,  public static AtomicLong tot_mgr_wait_for_zk_delete = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,58,  public static AtomicLong tot_mgr_unacquired_orphan_done = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,59,  public static AtomicLong tot_mgr_resubmit_threshold_reached =
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,60,    new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,61,  public static AtomicLong tot_mgr_missing_state_in_delete =
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,62,    new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,63,  public static AtomicLong tot_mgr_heartbeat = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,64,  public static AtomicLong tot_mgr_rescan = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,65,  public static AtomicLong tot_mgr_rescan_deleted = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,66,  public static AtomicLong tot_mgr_task_deleted = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,67,  public static AtomicLong tot_mgr_resubmit_unassigned = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,68,  public static AtomicLong tot_mgr_relist_logdir = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,69,  public static AtomicLong tot_mgr_resubmit_dead_server_task =
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,70,    new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,73,  public static AtomicLong tot_wkr_failed_to_grab_task_no_data =
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,74,    new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,75,  public static AtomicLong tot_wkr_failed_to_grab_task_exception =
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,76,    new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,77,  public static AtomicLong tot_wkr_failed_to_grab_task_owned =
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,78,    new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,79,  public static AtomicLong tot_wkr_failed_to_grab_task_lost_race =
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,80,    new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,81,  public static AtomicLong tot_wkr_task_acquired = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,82,  public static AtomicLong tot_wkr_task_resigned = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,83,  public static AtomicLong tot_wkr_task_done = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,84,  public static AtomicLong tot_wkr_task_err = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,85,  public static AtomicLong tot_wkr_task_heartbeat = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,86,  public static AtomicLong tot_wkr_task_acquired_rescan = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,87,  public static AtomicLong tot_wkr_get_data_queued = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,88,  public static AtomicLong tot_wkr_get_data_result = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,89,  public static AtomicLong tot_wkr_get_data_retry = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,90,  public static AtomicLong tot_wkr_preempt_task = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,91,  public static AtomicLong tot_wkr_task_heartbeat_failed = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,92,  public static AtomicLong tot_wkr_final_transistion_failed =
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,93,    new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,97,    Field[] flds = cl.getDeclaredFields();
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java,98,    for (Field fld : flds) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java,33,import org.apache.hadoop.hbase.RegionServerStatusProtocol;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java,83,  private Object grabTaskLock = new Object();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java,112,"          if (HLogSplitter.splitLogFile(rootdir,"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java,113,"              fs.getFileStatus(new Path(filename)), fs, conf, p, sequenceIdChecker) == false) {"
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java,252,      if (slt.isUnassigned() == false) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java,258,      if (attemptToOwnTask(true) == false) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java,280,          if (attemptToOwnTask(false) == false) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java,326,    return;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java,398,    SplitLogCounters.tot_wkr_final_transistion_failed.incrementAndGet();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java,399,    return;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java,534,    return;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java,561,      return;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java,577,      PREEMPTED();
hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java,215,          tot_wkr_final_transistion_failed.get() + tot_wkr_task_done.get() +
hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java,221,            tot_wkr_final_transistion_failed.get() + tot_wkr_task_done.get() +
hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java,229,"        ""tot_wkr_final_transistion_failed, tot_wkr_task_done, "" +"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/HTableInterface.java,83,"   * Method that does a batch call on Deletes, Gets and Puts. The ordering of"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/HTableInterface.java,84,   * execution of the actions is not defined. Meaning if you do a Put and a
hbase-server/src/main/java/org/apache/hadoop/hbase/client/HTableInterface.java,88,"   * @param actions list of Get, Put, Delete objects"
hbase-server/src/main/java/org/apache/hadoop/hbase/client/HTableInterface.java,101,"   * @param actions list of Get, Put, Delete objects"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9758,    // optional bool foundColumn = 5;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9759,    boolean hasFoundColumn();
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9760,    boolean getFoundColumn();
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9761,
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9762,    // optional bool matchedColumn = 6;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9763,    boolean hasMatchedColumn();
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9764,    boolean getMatchedColumn();
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9765,
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9766,    // optional bool filterIfMissing = 7;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9770,    // optional bool latestVersionOnly = 8;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9846,    // optional bool foundColumn = 5;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9847,    public static final int FOUNDCOLUMN_FIELD_NUMBER = 5;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9848,    private boolean foundColumn_;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9849,    public boolean hasFoundColumn() {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9850,      return ((bitField0_ & 0x00000010) == 0x00000010);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9851,    }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9852,    public boolean getFoundColumn() {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9853,      return foundColumn_;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9854,    }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9855,
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9856,    // optional bool matchedColumn = 6;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9857,    public static final int MATCHEDCOLUMN_FIELD_NUMBER = 6;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9858,    private boolean matchedColumn_;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9859,    public boolean hasMatchedColumn() {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9860,      return ((bitField0_ & 0x00000020) == 0x00000020);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9861,    }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9862,    public boolean getMatchedColumn() {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9863,      return matchedColumn_;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9864,    }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9865,
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9866,    // optional bool filterIfMissing = 7;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9867,    public static final int FILTERIFMISSING_FIELD_NUMBER = 7;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9870,      return ((bitField0_ & 0x00000040) == 0x00000040);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9876,    // optional bool latestVersionOnly = 8;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9877,    public static final int LATESTVERSIONONLY_FIELD_NUMBER = 8;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9880,      return ((bitField0_ & 0x00000080) == 0x00000080);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9891,      foundColumn_ = false;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9892,      matchedColumn_ = false;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9933,"        output.writeBool(5, foundColumn_);"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9936,"        output.writeBool(6, matchedColumn_);"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9937,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9938,      if (((bitField0_ & 0x00000040) == 0x00000040)) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9939,"        output.writeBool(7, filterIfMissing_);"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9940,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9941,      if (((bitField0_ & 0x00000080) == 0x00000080)) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9942,"        output.writeBool(8, latestVersionOnly_);"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9971,"          .computeBoolSize(5, foundColumn_);"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9975,"          .computeBoolSize(6, matchedColumn_);"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9976,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9977,      if (((bitField0_ & 0x00000040) == 0x00000040)) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9978,        size += com.google.protobuf.CodedOutputStream
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9979,"          .computeBoolSize(7, filterIfMissing_);"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9980,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9981,      if (((bitField0_ & 0x00000080) == 0x00000080)) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9982,        size += com.google.protobuf.CodedOutputStream
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,9983,"          .computeBoolSize(8, latestVersionOnly_);"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10028,      result = result && (hasFoundColumn() == other.hasFoundColumn());
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10029,      if (hasFoundColumn()) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10030,        result = result && (getFoundColumn()
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10031,            == other.getFoundColumn());
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10032,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10033,      result = result && (hasMatchedColumn() == other.hasMatchedColumn());
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10034,      if (hasMatchedColumn()) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10035,        result = result && (getMatchedColumn()
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10036,            == other.getMatchedColumn());
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10037,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10073,      if (hasFoundColumn()) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10074,        hash = (37 * hash) + FOUNDCOLUMN_FIELD_NUMBER;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10075,        hash = (53 * hash) + hashBoolean(getFoundColumn());
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10076,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10077,      if (hasMatchedColumn()) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10078,        hash = (37 * hash) + MATCHEDCOLUMN_FIELD_NUMBER;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10079,        hash = (53 * hash) + hashBoolean(getMatchedColumn());
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10080,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10218,        foundColumn_ = false;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10219,        bitField0_ = (bitField0_ & ~0x00000010);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10220,        matchedColumn_ = false;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10221,        bitField0_ = (bitField0_ & ~0x00000020);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10223,        bitField0_ = (bitField0_ & ~0x00000040);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10225,        bitField0_ = (bitField0_ & ~0x00000080);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10287,        result.foundColumn_ = foundColumn_;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10291,        result.matchedColumn_ = matchedColumn_;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10292,        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10293,          to_bitField0_ |= 0x00000040;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10294,        }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10295,        result.filterIfMissing_ = filterIfMissing_;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10296,        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10297,          to_bitField0_ |= 0x00000080;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10298,        }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10328,        if (other.hasFoundColumn()) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10329,          setFoundColumn(other.getFoundColumn());
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10330,        }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10331,        if (other.hasMatchedColumn()) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10332,          setMatchedColumn(other.getMatchedColumn());
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10333,        }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10415,              foundColumn_ = input.readBool();
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10420,              matchedColumn_ = input.readBool();
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10421,              break;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10422,            }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10423,            case 56: {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10424,              bitField0_ |= 0x00000040;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10425,              filterIfMissing_ = input.readBool();
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10426,              break;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10427,            }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10428,            case 64: {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10429,              bitField0_ |= 0x00000080;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10601,      // optional bool foundColumn = 5;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10602,      private boolean foundColumn_ ;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10603,      public boolean hasFoundColumn() {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10604,        return ((bitField0_ & 0x00000010) == 0x00000010);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10605,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10606,      public boolean getFoundColumn() {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10607,        return foundColumn_;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10608,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10609,      public Builder setFoundColumn(boolean value) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10610,        bitField0_ |= 0x00000010;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10611,        foundColumn_ = value;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10612,        onChanged();
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10613,        return this;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10614,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10615,      public Builder clearFoundColumn() {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10616,        bitField0_ = (bitField0_ & ~0x00000010);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10617,        foundColumn_ = false;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10618,        onChanged();
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10619,        return this;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10620,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10621,
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10622,      // optional bool matchedColumn = 6;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10623,      private boolean matchedColumn_ ;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10624,      public boolean hasMatchedColumn() {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10625,        return ((bitField0_ & 0x00000020) == 0x00000020);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10626,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10627,      public boolean getMatchedColumn() {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10628,        return matchedColumn_;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10629,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10630,      public Builder setMatchedColumn(boolean value) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10631,        bitField0_ |= 0x00000020;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10632,        matchedColumn_ = value;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10633,        onChanged();
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10634,        return this;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10635,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10636,      public Builder clearMatchedColumn() {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10637,        bitField0_ = (bitField0_ & ~0x00000020);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10638,        matchedColumn_ = false;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10639,        onChanged();
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10640,        return this;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10641,      }
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10642,
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10643,      // optional bool filterIfMissing = 7;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10646,        return ((bitField0_ & 0x00000040) == 0x00000040);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10652,        bitField0_ |= 0x00000040;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10658,        bitField0_ = (bitField0_ & ~0x00000040);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10664,      // optional bool latestVersionOnly = 8;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10667,        return ((bitField0_ & 0x00000080) == 0x00000080);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10673,        bitField0_ |= 0x00000080;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,10679,        bitField0_ = (bitField0_ & ~0x00000080);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,12703,"      ""r\""\352\001\n\027SingleColumnValueFilter\022\024\n\014columnF"" +"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,12706,"      ""tor\030\004 \002(\0132\013.Comparator\022\023\n\013foundColumn\030\005 "" +"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,12707,"      ""\001(\010\022\025\n\rmatchedColumn\030\006 \001(\010\022\027\n\017filterIfMi"" +"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,12708,"      ""ssing\030\007 \001(\010\022\031\n\021latestVersionOnly\030\010 \001(\010\""%"" +"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,12709,"      ""\n\nSkipFilter\022\027\n\006filter\030\001 \002(\0132\007.Filter\""&\n"","
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,12710,"      ""\020TimestampsFilter\022\022\n\ntimestamps\030\001 \003(\003\""4\n"" +"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,12711,"      ""\013ValueFilter\022%\n\rcompareFilter\030\001 \002(\0132\016.Co"" +"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,12712,"      ""mpareFilter\""+\n\020WhileMatchFilter\022\027\n\006filte"" +"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,12713,"      ""r\030\001 \002(\0132\007.FilterBB\n*org.apache.hadoop.hb"" +"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,12714,"      ""ase.protobuf.generatedB\014FilterProtosH\001\210\001"" +"
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,12715,"      ""\001\240\001\001"""
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/FilterProtos.java,12895,"              new java.lang.String[] { ""ColumnFamily"", ""ColumnQualifier"", ""CompareOp"", ""Comparator"", ""FoundColumn"", ""MatchedColumn"", ""FilterIfMissing"", ""LatestVersionOnly"", },"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java,89,   * @param foundColumn
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java,90,   * @param matchedColumn
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java,94,"  protected SingleColumnValueExcludeFilter(final byte[] family, final byte [] qualifier,"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java,95,"    final CompareOp compareOp, ByteArrayComparable comparator, final boolean foundColumn,"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java,96,"    final boolean matchedColumn, final boolean filterIfMissing, final boolean latestVersionOnly) {"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java,97,"    super(family,qualifier,compareOp,comparator,foundColumn,"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java,98,"      matchedColumn,filterIfMissing,latestVersionOnly);"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java,168,    return new SingleColumnValueExcludeFilter(
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java,169,"      parentProto.hasColumnFamily()?parentProto.getColumnFamily().toByteArray():null,"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java,170,"      parentProto.hasColumnQualifier()?parentProto.getColumnQualifier().toByteArray():null,"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java,171,"      compareOp, comparator, parentProto.getFoundColumn(),parentProto.getMatchedColumn(),"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueExcludeFilter.java,172,"      parentProto.getFilterIfMissing(),parentProto.getLatestVersionOnly());"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,131,   * @param foundColumn
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,132,   * @param matchedColumn
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,136,"  protected SingleColumnValueFilter(final byte[] family, final byte [] qualifier,"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,137,"    final CompareOp compareOp, ByteArrayComparable comparator, final boolean foundColumn,"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,138,"    final boolean matchedColumn, final boolean filterIfMissing, final boolean latestVersionOnly) {"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,139,"    this(family,qualifier,compareOp,comparator);"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,140,    this.foundColumn = foundColumn;
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,141,    this.matchedColumn = matchedColumn;
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,316,    builder.setFoundColumn(this.foundColumn);
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,317,    builder.setMatchedColumn(this.matchedColumn);
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,355,    return new SingleColumnValueFilter(
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,356,"      proto.hasColumnFamily()?proto.getColumnFamily().toByteArray():null,"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,357,"      proto.hasColumnQualifier()?proto.getColumnQualifier().toByteArray():null,"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,358,"      compareOp, comparator, proto.getFoundColumn(),proto.getMatchedColumn(),"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,359,"      proto.getFilterIfMissing(),proto.getLatestVersionOnly());"
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,376,      && this.foundColumn == other.foundColumn
hbase-server/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,377,      && this.matchedColumn == other.matchedColumn
hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterSerialization.java,260,"      CompareFilter.CompareOp.LESS_OR_EQUAL, new NullComparator(), false, true, false, false);"
hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterSerialization.java,277,"      CompareFilter.CompareOp.NOT_EQUAL, new NullComparator(), true, false, true, true);"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsckRepair.java,153,"    ProtobufUtil.closeRegion(rs, region.getRegionName(), false);"
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/MoveRegionsOfTableAction.java,62,"        admin.move(regionInfo.getRegionName(), Bytes.toBytes(destServerName));"
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/Action.java,117,    HBaseAdmin admin = this.context.getHaseIntegrationTestingUtility().getHBaseAdmin();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/Action.java,125,    HBaseAdmin admin = this.context.getHaseIntegrationTestingUtility().getHBaseAdmin();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/Action.java,142,    public IntegrationTestingUtility getHaseIntegrationTestingUtility() {
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/AddColumnAction.java,45,    this.admin = context.getHaseIntegrationTestingUtility().getHBaseAdmin();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/ChangeEncodingAction.java,49,    this.admin = context.getHaseIntegrationTestingUtility().getHBaseAdmin();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/ChangeVersionsAction.java,50,    this.admin = context.getHaseIntegrationTestingUtility().getHBaseAdmin();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/CompactRandomRegionOfTableAction.java,54,    HBaseTestingUtility util = context.getHaseIntegrationTestingUtility();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/CompactTableAction.java,49,    HBaseTestingUtility util = context.getHaseIntegrationTestingUtility();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/FlushRandomRegionOfTableAction.java,49,    HBaseTestingUtility util = context.getHaseIntegrationTestingUtility();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/FlushTableAction.java,45,    HBaseTestingUtility util = context.getHaseIntegrationTestingUtility();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/MergeRandomAdjacentRegionsOfTableAction.java,49,    HBaseTestingUtility util = context.getHaseIntegrationTestingUtility();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/MoveRandomRegionOfTableAction.java,53,    HBaseTestingUtility util = context.getHaseIntegrationTestingUtility();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/MoveRegionsOfTableAction.java,57,    HBaseAdmin admin = this.context.getHaseIntegrationTestingUtility().getHBaseAdmin();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/RemoveColumnAction.java,50,    this.admin = context.getHaseIntegrationTestingUtility().getHBaseAdmin();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/RestartRsHoldingTableAction.java,45,      Configuration conf = context.getHaseIntegrationTestingUtility().getConfiguration();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/SnapshotTableAction.java,42,    HBaseTestingUtility util = context.getHaseIntegrationTestingUtility();
hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/SplitRandomRegionOfTableAction.java,49,    HBaseTestingUtility util = context.getHaseIntegrationTestingUtility();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/AlreadyExists.java,232,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/BatchMutation.java,320,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/ColumnDescriptor.java,735,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,643,     * @param value value for perfomring the check
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,5136,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,5490,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,5868,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,6222,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,6600,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,7015,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,7420,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,7774,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,8140,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,8494,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,8785,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9175,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9626,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10064,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10523,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10956,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11500,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,12047,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,12511,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,12865,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13501,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14095,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14879,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15510,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16365,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17031,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17661,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18214,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18935,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19561,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20264,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20854,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21636,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22299,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22939,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23524,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24255,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24913,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25626,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26248,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27040,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27735,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28456,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29064,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29826,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,30471,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31079,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31646,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32327,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32931,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,33587,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34180,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34898,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,35413,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36122,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36674,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37229,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37703,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38071,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38430,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38818,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39206,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39834,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40345,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40890,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,41430,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42127,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42735,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43517,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44166,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44851,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,45459,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46229,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46874,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47729,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,48415,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,48824,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49312,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49871,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50394,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50882,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,51291,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,51874,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52389,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52842,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,53255,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,53669,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,54107,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,54372,     * value for perfomring the check
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,54399,       * value for perfomring the check
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,54688,     * value for perfomring the check
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,54700,     * value for perfomring the check
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,54970,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,55692,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/IOError.java,233,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/IllegalArgument.java,232,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Mutation.java,434,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TAppend.java,468,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TCell.java,305,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TColumn.java,300,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TIncrement.java,441,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TRegionInfo.java,627,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TRowResult.java,401,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TScan.java,728,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TAppend.java,533,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TAuthorization.java,242,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TCellVisibility.java,222,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TColumn.java,371,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TColumnIncrement.java,373,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TColumnValue.java,509,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,634,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,837,                org.apache.thrift.protocol.TList _list44 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,838,                struct.columns = new ArrayList<TColumn>(_list44.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,839,                for (int _i45 = 0; _i45 < _list44.size; ++_i45)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,841,                  TColumn _elem46; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,842,                  _elem46 = new TColumn();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,843,                  _elem46.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,844,                  struct.columns.add(_elem46);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,872,                org.apache.thrift.protocol.TMap _map47 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,873,"                struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map47.size);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,874,                for (int _i48 = 0; _i48 < _map47.size; ++_i48)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,876,                  ByteBuffer _key49; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,877,                  ByteBuffer _val50; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,878,                  _key49 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,879,                  _val50 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,880,"                  struct.attributes.put(_key49, _val50);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,922,            for (TColumn _iter51 : struct.columns)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,924,              _iter51.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,948,"            for (Map.Entry<ByteBuffer, ByteBuffer> _iter52 : struct.attributes.entrySet())"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,950,              oprot.writeBinary(_iter52.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,951,              oprot.writeBinary(_iter52.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1003,          for (TColumn _iter53 : struct.columns)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1005,            _iter53.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1018,"          for (Map.Entry<ByteBuffer, ByteBuffer> _iter54 : struct.attributes.entrySet())"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1020,            oprot.writeBinary(_iter54.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1021,            oprot.writeBinary(_iter54.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1038,"          org.apache.thrift.protocol.TList _list55 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1039,          struct.columns = new ArrayList<TColumn>(_list55.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1040,          for (int _i56 = 0; _i56 < _list55.size; ++_i56)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1042,            TColumn _elem57; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1043,            _elem57 = new TColumn();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1044,            _elem57.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1045,            struct.columns.add(_elem57);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1060,"          org.apache.thrift.protocol.TMap _map58 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1061,"          struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map58.size);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1062,          for (int _i59 = 0; _i59 < _map58.size; ++_i59)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1064,            ByteBuffer _key60; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1065,            ByteBuffer _val61; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1066,            _key60 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1067,            _val61 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1068,"            struct.attributes.put(_key60, _val61);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,2, * Autogenerated by Thrift Compiler (0.9.1)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,18,import org.apache.thrift.async.AsyncMethodCallback;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,19,import org.apache.thrift.server.AbstractNonblockingServer.*;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,48,"public class TGet implements org.apache.thrift.TBase<TGet, TGet._Fields>, java.io.Serializable, Cloneable, Comparable<TGet> {"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,205,      List<TColumn> __this__columns = new ArrayList<TColumn>(other.columns.size());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,221,"      Map<ByteBuffer,ByteBuffer> __this__attributes = new HashMap<ByteBuffer,ByteBuffer>(other.attributes);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,699,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,702,  @Override
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,710,    lastComparison = Boolean.valueOf(isSetRow()).compareTo(other.isSetRow());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,715,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.row, other.row);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,720,    lastComparison = Boolean.valueOf(isSetColumns()).compareTo(other.isSetColumns());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,725,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.columns, other.columns);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,730,    lastComparison = Boolean.valueOf(isSetTimestamp()).compareTo(other.isSetTimestamp());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,735,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.timestamp, other.timestamp);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,740,    lastComparison = Boolean.valueOf(isSetTimeRange()).compareTo(other.isSetTimeRange());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,745,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.timeRange, other.timeRange);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,750,    lastComparison = Boolean.valueOf(isSetMaxVersions()).compareTo(other.isSetMaxVersions());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,755,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.maxVersions, other.maxVersions);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,760,    lastComparison = Boolean.valueOf(isSetFilterString()).compareTo(other.isSetFilterString());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,765,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.filterString, other.filterString);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,770,    lastComparison = Boolean.valueOf(isSetAttributes()).compareTo(other.isSetAttributes());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,775,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.attributes, other.attributes);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,780,    lastComparison = Boolean.valueOf(isSetAuthorizations()).compareTo(other.isSetAuthorizations());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,785,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.authorizations, other.authorizations);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,948,                  TColumn _elem18;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,1000,                  ByteBuffer _key21;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,1001,                  ByteBuffer _val22;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,1191,            TColumn _elem29;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,1222,            ByteBuffer _key32;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,1223,            ByteBuffer _val33;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,2030,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,2480,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,2969,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,3417,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,3941,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4067,                  org.apache.thrift.protocol.TList _list124 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4068,                  struct.gets = new ArrayList<TGet>(_list124.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4069,                  for (int _i125 = 0; _i125 < _list124.size; ++_i125)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4071,                    TGet _elem126; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4072,                    _elem126 = new TGet();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4073,                    _elem126.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4074,                    struct.gets.add(_elem126);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4107,            for (TGet _iter127 : struct.gets)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4109,              _iter127.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4135,          for (TGet _iter128 : struct.gets)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4137,            _iter128.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4148,"          org.apache.thrift.protocol.TList _list129 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4149,          struct.gets = new ArrayList<TGet>(_list129.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4150,          for (int _i130 = 0; _i130 < _list129.size; ++_i130)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4152,            TGet _elem131; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4153,            _elem131 = new TGet();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4154,            _elem131.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4155,            struct.gets.add(_elem131);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4438,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4550,                  org.apache.thrift.protocol.TList _list132 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4551,                  struct.success = new ArrayList<TResult>(_list132.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4552,                  for (int _i133 = 0; _i133 < _list132.size; ++_i133)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4554,                    TResult _elem134; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4555,                    _elem134 = new TResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4556,                    _elem134.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4557,                    struct.success.add(_elem134);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4594,            for (TResult _iter135 : struct.success)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4596,              _iter135.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4635,            for (TResult _iter136 : struct.success)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4637,              _iter136.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4652,"            org.apache.thrift.protocol.TList _list137 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4653,            struct.success = new ArrayList<TResult>(_list137.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4654,            for (int _i138 = 0; _i138 < _list137.size; ++_i138)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4656,              TResult _elem139; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4657,              _elem139 = new TResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4658,              _elem139.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4659,              struct.success.add(_elem139);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4963,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,5352,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,6138,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,6743,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7252,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7378,                  org.apache.thrift.protocol.TList _list140 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7379,                  struct.puts = new ArrayList<TPut>(_list140.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7380,                  for (int _i141 = 0; _i141 < _list140.size; ++_i141)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7382,                    TPut _elem142; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7383,                    _elem142 = new TPut();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7384,                    _elem142.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7385,                    struct.puts.add(_elem142);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7418,            for (TPut _iter143 : struct.puts)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7420,              _iter143.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7446,          for (TPut _iter144 : struct.puts)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7448,            _iter144.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7459,"          org.apache.thrift.protocol.TList _list145 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7460,          struct.puts = new ArrayList<TPut>(_list145.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7461,          for (int _i146 = 0; _i146 < _list145.size; ++_i146)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7463,            TPut _elem147; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7464,            _elem147 = new TPut();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7465,            _elem147.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7466,            struct.puts.add(_elem147);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7670,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,8120,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,8509,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,8979,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9105,                  org.apache.thrift.protocol.TList _list148 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9106,                  struct.deletes = new ArrayList<TDelete>(_list148.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9107,                  for (int _i149 = 0; _i149 < _list148.size; ++_i149)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9109,                    TDelete _elem150; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9110,                    _elem150 = new TDelete();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9111,                    _elem150.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9112,                    struct.deletes.add(_elem150);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9145,            for (TDelete _iter151 : struct.deletes)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9147,              _iter151.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9173,          for (TDelete _iter152 : struct.deletes)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9175,            _iter152.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9186,"          org.apache.thrift.protocol.TList _list153 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9187,          struct.deletes = new ArrayList<TDelete>(_list153.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9188,          for (int _i154 = 0; _i154 < _list153.size; ++_i154)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9190,            TDelete _elem155; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9191,            _elem155 = new TDelete();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9192,            _elem155.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9193,            struct.deletes.add(_elem155);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9476,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9588,                  org.apache.thrift.protocol.TList _list156 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9589,                  struct.success = new ArrayList<TDelete>(_list156.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9590,                  for (int _i157 = 0; _i157 < _list156.size; ++_i157)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9592,                    TDelete _elem158; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9593,                    _elem158 = new TDelete();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9594,                    _elem158.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9595,                    struct.success.add(_elem158);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9632,            for (TDelete _iter159 : struct.success)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9634,              _iter159.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9673,            for (TDelete _iter160 : struct.success)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9675,              _iter160.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9690,"            org.apache.thrift.protocol.TList _list161 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9691,            struct.success = new ArrayList<TDelete>(_list161.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9692,            for (int _i162 = 0; _i162 < _list161.size; ++_i162)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9694,              TDelete _elem163; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9695,              _elem163 = new TDelete();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9696,              _elem163.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9697,              struct.success.add(_elem163);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,10337,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,10942,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,11431,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,11879,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,12375,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,12823,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,13319,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,13769,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14251,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14783,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14913,                  org.apache.thrift.protocol.TList _list164 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14914,                  struct.success = new ArrayList<TResult>(_list164.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14915,                  for (int _i165 = 0; _i165 < _list164.size; ++_i165)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14917,                    TResult _elem166; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14918,                    _elem166 = new TResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14919,                    _elem166.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14920,                    struct.success.add(_elem166);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14966,            for (TResult _iter167 : struct.success)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14968,              _iter167.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15015,            for (TResult _iter168 : struct.success)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15017,              _iter168.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15035,"            org.apache.thrift.protocol.TList _list169 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15036,            struct.success = new ArrayList<TResult>(_list169.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15037,            for (int _i170 = 0; _i170 < _list169.size; ++_i170)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15039,              TResult _elem171; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15040,              _elem171 = new TResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15041,              _elem171.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15042,              struct.success.add(_elem171);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15271,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15686,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,16179,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,16568,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17093,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17601,      return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17713,                  org.apache.thrift.protocol.TList _list172 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17714,                  struct.success = new ArrayList<TResult>(_list172.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17715,                  for (int _i173 = 0; _i173 < _list172.size; ++_i173)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17717,                    TResult _elem174; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17718,                    _elem174 = new TResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17719,                    _elem174.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17720,                    struct.success.add(_elem174);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17757,            for (TResult _iter175 : struct.success)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17759,              _iter175.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17798,            for (TResult _iter176 : struct.success)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17800,              _iter176.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17815,"            org.apache.thrift.protocol.TList _list177 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17816,            struct.success = new ArrayList<TResult>(_list177.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17817,            for (int _i178 = 0; _i178 < _list177.size; ++_i178)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17819,              TResult _elem179; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17820,              _elem179 = new TResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17821,              _elem179.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17822,              struct.success.add(_elem179);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TIOError.java,227,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TIllegalArgument.java,226,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TIncrement.java,540,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TMutation.java,334,  /**
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TMutation.java,335,"   * If you'd like this to perform more respectably, use the hashcode generator option."
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TMutation.java,336,   */
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TMutation.java,339,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TMutation.java,341,
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,2, * Autogenerated by Thrift Compiler (0.9.1)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,18,import org.apache.thrift.async.AsyncMethodCallback;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,19,import org.apache.thrift.server.AbstractNonblockingServer.*;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,47,"public class TPut implements org.apache.thrift.TBase<TPut, TPut._Fields>, java.io.Serializable, Cloneable, Comparable<TPut> {"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,199,      List<TColumnValue> __this__columnValues = new ArrayList<TColumnValue>(other.columnValues.size());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,207,"      Map<ByteBuffer,ByteBuffer> __this__attributes = new HashMap<ByteBuffer,ByteBuffer>(other.attributes);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,592,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,595,  @Override
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,603,    lastComparison = Boolean.valueOf(isSetRow()).compareTo(other.isSetRow());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,608,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.row, other.row);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,613,    lastComparison = Boolean.valueOf(isSetColumnValues()).compareTo(other.isSetColumnValues());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,618,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.columnValues, other.columnValues);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,623,    lastComparison = Boolean.valueOf(isSetTimestamp()).compareTo(other.isSetTimestamp());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,628,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.timestamp, other.timestamp);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,633,    lastComparison = Boolean.valueOf(isSetAttributes()).compareTo(other.isSetAttributes());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,638,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.attributes, other.attributes);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,643,    lastComparison = Boolean.valueOf(isSetDurability()).compareTo(other.isSetDurability());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,648,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.durability, other.durability);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,653,    lastComparison = Boolean.valueOf(isSetCellVisibility()).compareTo(other.isSetCellVisibility());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,658,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.cellVisibility, other.cellVisibility);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,803,                  TColumnValue _elem36;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,830,                  ByteBuffer _key39;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,831,                  ByteBuffer _val40;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,996,          TColumnValue _elem47;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,1014,            ByteBuffer _key50;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,1015,            ByteBuffer _val51;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TResult.java,320,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,321,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,447,                org.apache.thrift.protocol.TList _list98 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,448,                struct.mutations = new ArrayList<TMutation>(_list98.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,449,                for (int _i99 = 0; _i99 < _list98.size; ++_i99)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,451,                  TMutation _elem100; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,452,                  _elem100 = new TMutation();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,453,                  _elem100.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,454,                  struct.mutations.add(_elem100);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,487,          for (TMutation _iter101 : struct.mutations)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,489,            _iter101.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,515,        for (TMutation _iter102 : struct.mutations)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,517,          _iter102.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,528,"        org.apache.thrift.protocol.TList _list103 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,529,        struct.mutations = new ArrayList<TMutation>(_list103.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,530,        for (int _i104 = 0; _i104 < _list103.size; ++_i104)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,532,          TMutation _elem105; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,533,          _elem105 = new TMutation();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,534,          _elem105.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,535,          struct.mutations.add(_elem105);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,2, * Autogenerated by Thrift Compiler (0.9.1)
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,18,import org.apache.thrift.async.AsyncMethodCallback;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,19,import org.apache.thrift.server.AbstractNonblockingServer.*;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,39,"public class TScan implements org.apache.thrift.TBase<TScan, TScan._Fields>, java.io.Serializable, Cloneable, Comparable<TScan> {"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,218,      List<TColumn> __this__columns = new ArrayList<TColumn>(other.columns.size());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,235,"      Map<ByteBuffer,ByteBuffer> __this__attributes = new HashMap<ByteBuffer,ByteBuffer>(other.attributes);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,865,    return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,868,  @Override
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,876,    lastComparison = Boolean.valueOf(isSetStartRow()).compareTo(other.isSetStartRow());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,881,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.startRow, other.startRow);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,886,    lastComparison = Boolean.valueOf(isSetStopRow()).compareTo(other.isSetStopRow());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,891,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.stopRow, other.stopRow);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,896,    lastComparison = Boolean.valueOf(isSetColumns()).compareTo(other.isSetColumns());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,901,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.columns, other.columns);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,906,    lastComparison = Boolean.valueOf(isSetCaching()).compareTo(other.isSetCaching());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,911,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.caching, other.caching);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,916,    lastComparison = Boolean.valueOf(isSetMaxVersions()).compareTo(other.isSetMaxVersions());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,921,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.maxVersions, other.maxVersions);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,926,    lastComparison = Boolean.valueOf(isSetTimeRange()).compareTo(other.isSetTimeRange());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,931,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.timeRange, other.timeRange);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,936,    lastComparison = Boolean.valueOf(isSetFilterString()).compareTo(other.isSetFilterString());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,941,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.filterString, other.filterString);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,946,    lastComparison = Boolean.valueOf(isSetBatchSize()).compareTo(other.isSetBatchSize());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,951,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.batchSize, other.batchSize);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,956,    lastComparison = Boolean.valueOf(isSetAttributes()).compareTo(other.isSetAttributes());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,961,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.attributes, other.attributes);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,966,    lastComparison = Boolean.valueOf(isSetAuthorizations()).compareTo(other.isSetAuthorizations());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,971,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.authorizations, other.authorizations);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,976,    lastComparison = Boolean.valueOf(isSetReversed()).compareTo(other.isSetReversed());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,981,"      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.reversed, other.reversed);"
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1173,                  TColumn _elem108;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1233,                  ByteBuffer _key111;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1234,                  ByteBuffer _val112;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1480,            TColumn _elem119;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1515,            ByteBuffer _key122;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1516,            ByteBuffer _val123;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TTimeRange.java,289,    return 0;
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,95,    sb.append(Bytes.toStringBinary(name));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,97,    sb.append(Bytes.toStringBinary(row));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,107,          sb.append(Bytes.toStringBinary((byte[])e.getKey()));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,111,            sb.append(Bytes.toStringBinary((byte[])e.getKey()));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,116,              sb.append(Bytes.toStringBinary((byte[])o));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,118,"              sb.append(Bytes.toStringBinary(((KeyValue) o).getQualifierArray(),"
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,119,"                ((KeyValue) o).getQualifierOffset(), ((KeyValue) o).getQualifierLength()));"
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,154,    sb.append(Bytes.toStringBinary(name));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,166,      sb.append(Bytes.toStringBinary(rk));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,214,   * @param client
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,215,   * @param name
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,223,   * @param client
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,224,   * @param conf
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,225,   * @param name
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,233,   * @param client
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,234,   * @param conf
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,235,   * @param name
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,263,    sb.append(Bytes.toStringBinary(name));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,405,    sb.append(Bytes.toStringBinary(name));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,407,    sb.append(Bytes.toStringBinary(put.getRow()));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,462,    sb.append(Bytes.toStringBinary(name));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,533,      sb.append(Bytes.toStringBinary(name));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,687,    sb.append(Bytes.toStringBinary(name));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,689,    sb.append(Bytes.toStringBinary(put.getRow()));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,731,    sb.append(Bytes.toStringBinary(name));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/RemoteHTable.java,733,    sb.append(Bytes.toStringBinary(row));
hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java,62,"  private static final TableName TABLE = TableName.valueOf(""TestRemoteTable"");"
hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java,63,"  private static final byte[] ROW_1 = Bytes.toBytes(""testrow1"");"
hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java,64,"  private static final byte[] ROW_2 = Bytes.toBytes(""testrow2"");"
hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java,65,"  private static final byte[] ROW_3 = Bytes.toBytes(""testrow3"");"
hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java,66,"  private static final byte[] ROW_4 = Bytes.toBytes(""testrow4"");"
hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java,67,"  private static final byte[] COLUMN_1 = Bytes.toBytes(""a"");"
hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java,68,"  private static final byte[] COLUMN_2 = Bytes.toBytes(""b"");"
hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java,69,"  private static final byte[] COLUMN_3 = Bytes.toBytes(""c"");"
hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java,70,"  private static final byte[] QUALIFIER_1 = Bytes.toBytes(""1"");"
hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java,71,"  private static final byte[] QUALIFIER_2 = Bytes.toBytes(""2"");"
hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java,325,"    assertTrue(Bytes.equals(Bytes.toBytes(""TestRemoteTable""), remoteTable.getTableName()));"
